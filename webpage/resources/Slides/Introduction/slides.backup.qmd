---
title: "Use GenomeDK"
subtitle: "An introduction to the GDK system and basic commands https://hds-sandbox.github.io/GDKworkshops"
author: 
    - "Samuele Soraggi"
    - "Dan Søndergaard"
institute:
    - Health Data Science sandbox, BiRC
    - GenomeDK, Health
date: last-modified
format: 
  revealjs:
    chalkboard: true
toc: false
toc-depth: 1
slide-number: h.v
code-line-numbers: false
logo: img/logos.png
navigation-mode: vertical
---

# Some background

- These slides are both a presentation and a small reference manual

- We will try out some commands during the workshop

- Official reference documentation: [genome.au.dk](https://genome.au.dk)

## When you need to ask for help

- **Practical help:** 
  
  Samuele (BiRC, MBG) - samuele@birc.au.dk 

- **Drop in hours:**

  - Bioinformatics Cafe: [https://abc.au.dk](abc.au.dk), abc@au.dk
  - Samuele (BiRC, MBG) - samuele@birc.au.dk

- **General mail for assistance**

  support@genome.au.dk

## Program

- **10:00-11:00**: What is GenomeDK, File System, virtual environments

- **11:00-12:00**: Exercise: access interface, new environment, transfer data, interactive job

- **12:45-13:15**: queueing system and jobs, estimate resource usage

- **13:15-14:00**: Send out your first job with `slurm`, estimate resource usage

## Get the slides

Webpage: [https://hds-sandbox.github.io/GDKworkshops/](https://hds-sandbox.github.io/GDKworkshops/)

![Slides will always be up to date in this webpage](./img/webpageGDK.png)

## Navigate the slides

![](./img/slideGuide.png){fig-align="center"}


## Software for command line{.smaller} 
:::: {.columns}
::: {.column width="50%" }
The basic softwares

![Powershell for windows](img/powershell.png){width=250px fig-align="center"}

![Terminal for MacOS and Linux](img/terminal.png){width=250px fig-align="center"}

:::
::: {.column width="50%" }

Customizable 

![Terminator for Linux - iTerm2 for MacOS](img/terminator.png){width=250px fig-align="center" } 

![Tabby for Linux, MacOS, Windows](img/tabby.png){width=250px fig-align="center"}

:::
::::

# GenomeDK's ABC

Learn your way around the basics of the `GenomeDK` cluster.

## Infrastructure

`GenomeDK` is a **computing cluster**, i.e. a set of interconnected computers (nodes). `GenomeDK` has:

- **computing nodes** used for running programs (~15000 cores)
- **storage nodes** storing data in many hard drives (~23 PiB)
- a **network** making nodes talk to each other
- a **frontend** node from which you can send your programs to a node to be executed
- a **queueing system** called *slurm* to prioritize the users' program to be run

---

![](./img/Main-components-of-a-computer-cluster.png){fig-align="center"}

## Access 

- **Creating an account** happens through [this form](https://console.genome.au.dk/user-requests/create/) at genome.au.dk

    ![](img/account.png){width=600px fig-alig="center"}

---

- **Logging into GenomeDK** happens through the command ^[both in Linux/Mac terminal and Windows Powershell. Powershell might require `ssh.exe` instead of `ssh`]

    ```{.bash}
    [local]$  ssh USERNAME@login.genome.au.dk
    ```

- When first logged in, **setup the 2-factor authentication** by 
    - showing a QR-code with the command

        ```{.bash}
        [gdk]$  gdk-auth-show-qr
        ```
    - scanning it with your phone's Authenticator app ^[e.g. Microsoft Authenticator, Google Authenticator, ...].


## Access without password

It is nice to avoid writing the password at every access. If you are on the cluster, exit from it to go back to your local computer

```{.bash}
[gdk]$  exit
```

&nbsp;

Now we set up a public-key authentication. We generate a key pair (public and private):

```{.bash}
[local]$  ssh-keygen -t ed25519
```

Always press <kbd>Enter</kbd> and do not insert any password when asked. 

---

and create a folder on the cluster called `.ssh` to contain the public key

```{.bash}
[local]$  ssh USERNAME@login.genome.au.dk mkdir -p .ssh
```
&nbsp;

and finally send the public key to the cluster, into the file `authorized_keys`

```{.bash}
[local]$  cat ~/.ssh/id_rsa.pub | ssh USERNAME@login.genome.au.dk 'cat >> .ssh/authorized_keys'
```
&nbsp;

After this, your local private key will be tested against GenomeDK's public key every time you log in, without you needing to write a password.

# File System (FS) on GenomeDK

- Directory structure
- Absolute and Relative Paths
- important folders
- navigate the FS on the command line

## How the FS is organized

:::: {.columns}

::: {.column width="60%" }

Folders and files follow a tree-like structure

- `/` is the root folder of the filesystem - nothing is above that
- the FS is shared across all machines and available to all users 
- `home` and `faststorage` are two of the folders in the root
- projects are in `/faststorage/project` and **linked** to your home

:::

::: {.column width="40%"}

![](img/complexTree.png){fig-align="center" width=350px}

:::

::::

---


## Exercise: 

Log in: `ssh USERNAME@login.genome.au.dk`

:::{.callout-note}
Run a command = Type a command + Enter
:::

- Run `pwd`, You should see your home folder: `/home/USERNAME`
    - `/home/USERNAME` is an example of **path**.
    - `pwd` shows your current folder (WD, Working Directory)
    - you can write paths starting FROM the WD!

---

- Run `ls .` to show the content of your WD (the dot `.`)

- Run `mkdir -p GDKintro` to create a `GDKintro` folder

- Run `echo "hello" > ./GDKintro/file.txt` to write hello in a file

- Use `ls ./GDKintro` to see if the text file is there.

:::{.callout-tip title="Relative and absolute paths"}
- `/home/USERNAME` starts from the root `/`. It is an **absolute path**.
- `./GDKintro` starts from the WD. It is a **relative path**.
:::


---

Look at the File system tree and answer to the following questions:

:::: {.columns}
::: {.column width="40%" }
![](img/complexTree.png){width=300px}
:::
::: {.column width="60%" }
```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/paths.json'
display_quiz("./questions/paths.json", shuffle_answers=True, question_alignment="left")
```
:::
::::
---

### Something more about your home

After log in, you will find yourself into your private **home folder**, denoted by `~` or equivalently `/home/username`. Your prompt will look like this:

&nbsp;

```{.bash}
[username@node ~] 
```
which follows the format **[username@node current_folder]**.

&nbsp;

:::{.callout-warning}
- Do not fill up your home folder with data. It has a **limited amount of storage** (a quota of 100GB).
- Your home folder is only **private to you**
:::

---

## Exercise cont'd

We now set the WD into `GDKintro` and remove all text files in it. Then we download a zipped `fastq` file, unzip it, and print a preview!


```{.bash}
cd GDKintro

rm *.txt

wget https://github.com/hartwigmedical/testdata/raw/master/100k_reads_hiseq/TESTX/TESTX_H7YRLADXX_S1_L001_R1_001.fastq.gz \
     -O ./data.fastq.gz

gunzip data.fastq.gz

head data.fastq 
```

---

### Some notes about the commands

- `rm *.txt` removes all files ending with `.txt`. The symbol `*` is a wildcard for the file name

  :::{.callout-warning title="Forever away"}
  There is no trash bin - **removed files are lost forever** - with no exception
  :::

- `head` prints the first lines of a text file



## Exercise: Read files

Useful utility 1: `less` file reader. `less` is perfect for exploring (big) text files: you can scroll with the arrows, and quit pressing `q`. Try

```{.bash}

less data.fastq

```

&nbsp;
The very first sequence you see should be

```
@HISEQ_HU01:89:H7YRLADXX:1:1101:1116:2123 1:N:0:ATCACG
TCTGTGTAAATTACCCAGCCTCACGTATTCCTTTAGAGCAATGCAAAACAGACTAGACAAAAGGCTTTTAAAAGTCTA
ATCTGAGATTCCTGACCAAATGT
+
CCCFFFFFHHHHHJJJJJJJJJJJJHIJJJJJJJJJIJJJJJJJJJJJJJJJJJJJHIJGHJIJJIJJJJJHHHHHHH
FFFFFFFEDDEEEEDDDDDDDDD
```

The first line is metadata, the second is the sequence, then you have an empty line (symbol +), and the quality scores (encoded by letters as in [this table](https://learn.gencore.bio.nyu.edu/ngs-file-formats/quality-scores/)).

---


:::{.callout-tip title="Exercise" icon=false}
Search online (or with `less --help)` how to look for a specific word in a file with `less`. Then visualize the data with `less`, and try to find if there is any sequence of ten adjacent `N`s (which is, ten missing nucleotides). Then, answer the question below 

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/less.json'
display_quiz("./questions/less.json", shuffle_answers=True, question_alignment="center")
```
:::

## Exercise: Writing on files

Useful utility 2: `nano` text editor. It open, edits and saves text files. Very useful for changes on the fly.

- Try `nano data.fastq`. Change a base in the first sequence, 

- then press Ctrl+O to save (give it a new file name `newData.fastq` and press Enter)

- press Ctrl+X to exit. If you use `ls` you can see the new saved file.


# Package/Environment management

&nbsp;

- **No preinstalled software** on GenomeDK

- You install and manage your **software and its dependencies** inside virtual environments

## Virtual environments

Each project needs specific software versions dependent on each other for **reproducibility** - without interferring with other projects.

&nbsp;

:::{.callout-note title="Definition"}
A **virtual environment** keeps project-specific softwares and their dependencies separated 

&nbsp;

A **package manager** is a software that can retrieve, download, install, upgrade packages **easily and reliably**
:::
---

![](./img/virtualenvs.png)

## Exercise - Pixi

First of all, we open the desktop interface to GenomeDK at [desktop.genome.au.dk](https://desktop.genome.au.dk). Choose the Front end for the login.

The desktop session will be operative even if you close and reopen your browser afterwards!

![The terminal will work as if you logged into the frontend (The desktop is logged into the front-end node already). You can also use the browser!](img/desktop.png)

---

Open the terminal and run the command below to install `pixi`:

```{.bash}
curl -fsSL https://pixi.sh/install.sh | bash
```

After that, make the system recognize `pixi`

```{.bash}
echo PATH="$PATH:$HOME/.pixi/bin" >> ~/.bashrc
echo 'eval "$(pixi completion --shell bash)"'  >> ~/.bashrc
source ~/.bashrc
```

---

Change your WD with the one we created earlier, where we have the file `data.fastq`

```{.bash}
cd ~/GDKintro
```

Initiate a new pixi environment into the folder:

```{.bash}
pixi init
```

---

Use the file browser and open the `GDKintro` folder

![](img/gdkintroFolder.png){fig-align="center" width="800px"}

You can see some new files. `pixi.toml` contains info `pixi` will use to create your environment.

---

Open `pixi.toml` with the text editor, and make sure you have the two channels `conda-forge` and `bioconda`. If not, modify the file so the channel list is like below.

![](img/pixitoml.png){fig-align="center" width="800px"}

---

Now get back to the terminal and install some packages. This is done easily.

```{.bash}
pixi add rstudio-desktop jupyterlab r-ggplot2 r-dplyr pandas
```

It will look like this at the end

![](img/pixiInstalled.png){fig-align="center" width="800px"}

---

Now open the `pixi.toml` file. You should see all the installed packages with related information.

## Conda

&nbsp;

Conda is **both** a virtual environment and a package manager.

- easy to use and understand
- can handle quite big environments
- environments are easily shareable
- a [large archive](https://anaconda.org) (Anaconda) of packages
- active community of people archiving their packages on Anaconda

## Pixi

A newer virtual env. and package manager

&nbsp;

- An upgrade of Conda in speed and stability
- Can install the same packages as conda

## Exercise: Virt.Env. for Rstudio and Jupyterlab


---

Open the terminal and install conda with the following commands.

```{.bash}
wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O miniforge.sh
chmod +x miniforge.sh
bash miniforge.sh -b
./miniforge3/bin/conda init bash
```

&nbsp;

After a few `ENTER`s and `YES`'s you should get the installation done. Run

```{.bash}
source ~/.bashrc
```

and doublecheck that `conda` works:

```{.bash}
conda info
```

---

**Configuration**

You can add some default *channels* where to find archived packages. Here are some tipycal ones

```{.bash}
conda config --append channels conda-forge
conda config --append channels bioconda
```

We tell `conda` to consider channels in the order specified above. We also avoid opening the `base` environment (where `conda` is installed) at login.

```{.bash}
conda config --set channel_priority strict
conda config --set auto_activate_base false
```

**Base environment**

`base` is the environment containing conda itself. The current environment is in your prompt in round brackets.

```{.bash}
(environment) [samuele@fe-open-02 ~]$
```

We update Conda with `libmamba solver` - a lot faster in installing many packages at once.

```{.bash}
conda install -n base --yes conda-libmamba-solver
conda config --set solver libmamba
```

:::{.callout-warning title="Don't touch the Base"}
This is **the only time** you should install in the `base` environment! You might otherwise ruin the conda installation.
:::

---

**Create an environment**

An empty environment called `test_1`:

```{.bash}
conda create -n test_1
```

&nbsp;

You can list all the environments available:

```{.bash}
conda env list
```
```
> # conda environments:
> #
> base      *  /home/samuele/miniconda3
> test_1       /home/samuele/miniconda3/envs/test_1
```

:::{.callout-note}
An environment is in reality a folder, which contains all installed packages and other configurations and utilities
:::

---


**Activate and deactivate**

To use an environment we activate it:

```{.bash}
conda activate test_1
```
From now on, all installed softwares and packages will be available. `(test_1)` is now shown in your prompt.

&nbsp;

Deactivation happens by

```{.bash}
conda deactivate
```

---

**Package installation**

Conda puts together the dependency trees of requested packages to find all compatible dependencies versions.

![Figure: A package's dependency tree with required versions on the edges](img/condatree.png)

---

To install a specific package in your environment, search it on [anaconda.org](https://anaconda.org):

![Figure: search DeSeq2 for R](img/anaconda1.png)

---

![Figure: suggested commands to install the package](img/anaconda2.png){width=10cm}

:::{.callout-note title="Channels"}

packages are archived in channels. Typical ones are  `conda-forge` and `bioconda`.

`conda-forge` packages are often more up-to-date, but a few times show compatibility problems with other packages.
:::

---

Install a few packages in the activated environment - you can always specify a version restriction to each package:

```{.bash}
conda activate test_1
conda install bioconductor-deseq2 r-tidyr rstudio-desktop jupyterlab
```

:::{.callout-note}
To install few packages, you need more than a hundred installations! Those are all dependencies arising from the **comparison of dependency trees**.
:::


---

### Installation from a list of packages

You can export all the packages you have installed over time in your environment:

```{.bash}
conda env export --from-history > environment.yml
```

which looks like 

```{.yaml}
name: test_1
channels:
 - bioconda
 - conda-forge
 - defaults
 - r
dependencies:
 - bioconda::bioconductor-deseq2
 - conda-forge::r-tidyr
 ...
```

---

The same command without `--from-history` will create a very long file with ALL dependencies:

```{.yaml}
name: test_1
channels:
  - bioconda
  - conda-forge
  - defaults
  - r
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - _r-mutex=1.0.1=anacondar_1
  - argcomplete=3.2.2=pyhd8ed1ab_0
  ...
```

This is guaranteed to work **only on a system with same OS and architecture** as GenomeDK (Linux and x86)!

---

You can use the `yml` file to create an environment:

&nbsp;

```
conda env create -p test_1_from_file -f ./environment.yml
```

&nbsp;

Environment files are very useful when you want to **share environments with others**, especially when the package list is long.

---

**Good practice:** You want to install a lot of packages in an environment? Clone it first!
If you break something, you still have the old copy.

```{.bash}
conda create -p test_1_cloned --clone test_1
```

&nbsp;

If installations in the cloned environment go fine, then you can remove it 

```{.bash}
conda env remove -n test_1_cloned
```

and repeat the installations on the original one.

---

## Useful links for conda:

- [Conda cheat sheet](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf) with all the things you can do to manage environments

- [Anaconda](http://anaconda.org) where you can search for packages








# Working with Files {.hidden}

Moving, Downloading, Manipulating and other basic operation on files.

## File formats

Many files you use in bioinformatics are nothing else than text files which are written in a specific matter. This specific way of arranging the text in the files gives you many of the **file formats** you encounter when doing bioinformatics. 

&nbsp;

:::{.callout-note}
Some file formats are encoded differently than with plain ASCII text, and cannot usually be seen with a text editor.
:::

---

:::: {.columns}
::: {.column width="50%" }
![A text file is human-readable with any text reader or editor, and is composed of only ASCII characters, such as in the `fastq` file format](img/textfile.png)
:::
::: {.column width="50%" }
![A binary file containes other than ASCII characters. For example, the `bam` file format is binary and can be read with the `samtools` software.](img/binaryFile.png)
:::
::::

---



Let's get ready. Be sure you are in `myFolder` (use `pwd`) - Otherwise use 
```{.bash}
cd ~/myFolder
```

&nbsp;

Now, you can decompress the file `data.fastq.gz`, which is in `gz` compressed format:

```{.bash}
gunzip data.fastq.gz
```

:::{.callout-tip}
For compressing a file into `gz` format, you can use `gzip`. For compressing and decompressing in `zip` format, you have also the commands `zip` and `unzip`.
:::

---

## Less for reading files

`less` is perfect for reading text files: you can scroll with the arrows, and quit pressing `q`. Try

```{.bash}

less data.fastq

```

&nbsp;
The very first sequence you see should be

```
@HISEQ_HU01:89:H7YRLADXX:1:1101:1116:2123 1:N:0:ATCACG
TCTGTGTAAATTACCCAGCCTCACGTATTCCTTTAGAGCAATGCAAAACAGACTAGACAAAAGGCTTTTAAAAGTCTA
ATCTGAGATTCCTGACCAAATGT
+
CCCFFFFFHHHHHJJJJJJJJJJJJHIJJJJJJJJJIJJJJJJJJJJJJJJJJJJJHIJGHJIJJIJJJJJHHHHHHH
FFFFFFFEDDEEEEDDDDDDDDD
```

The first line is metadata, the second is the sequence, then you have an empty line (symbol +), and the quality scores (encoded by letters as in [this table](https://learn.gencore.bio.nyu.edu/ngs-file-formats/quality-scores/)).

---


:::{.callout-tip title="Exercise" icon=false}
Search online (or with `less --help)` how to look for a specific word in a file with `less`. Then visualize the data with `less`, and try to find if there is any sequence of ten adjacent `N`s (which is, ten missing nucleotides). Then, answer the question below 

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/less.json'
display_quiz("./questions/less.json", shuffle_answers=True, question_alignment="center")
```
:::

---

## Counting

How many lines are there in your file? The command `wc` can show that to you:

```{.bash}
wc -l data.fastq
```

&nbsp;


The file has 100000 lines, or 25000 sequences (each sequence is defined by 4 lines). 

&nbsp;

:::{.callout-tip}
`wc` has many functionalities. As always, look for the manual or examples to see how you can use it in other many ways.
:::

---

## Copy and Move

`cp` can copy one or more files - we use it on our data:

```{.bash}
cp data.fastq dataCopy.fastq
```

&nbsp;

`mv` moves a file into another folder - here we move it into our WD, which simply changes its filename:

```{.bash}
mv data.fastq ./dataOriginal.fastq
```

---

Use now `ls -lah` and you will see  two files of identical size and different creation dates. 

&nbsp;

Well, we changed our mind and do not want a copy of our data. Remove it with

```{.bash}
rm dataCopy.fastq
```

:::{.callout-warning title="Forever away"}
There is no trash bin - **removed files are lost forever** - with no exception
:::
---

## Writing on a file

Write something on a file using `>`:

```{.bash}
head -4 dataOriginal.fastq > smallFile.fastq
```

&nbsp;

prints out the first four lines of the data into `smallFile.fastq`.

&nbsp;

:::{.callout-warning}

Using again `>` will **overwrite** the file!

:::


---

Print out on the screen:

```{.bash}
cat smallFile.fastq
```

&nbsp;

Avoid overwriting by appending with `>>`:

```{.bash}
tail -4 dataOriginal.fastq >> smallFile.fastq
```

appends the last 4 lines of the data to `smallFile.fastq`. Check again using `cat` or `wc -l`.  

---

## Piping


You can create **small pipelines** directly on the shell with the symbol `|`. The output of a command and send it to the next command when you have `|` in between. For example, 

```{.bash}
grep NNNNN dataOriginal.fastq
```

finds the pattern `NNNNN` in the data.

How to find it in the first hundred sequences? Easy! we *pipe* `head` into *grep*:

```{.bash}
head -400 dataOriginal.fastq | grep NNNNN
```

---


The output of that pipe was a small output on screen - but **outputs can be huge**! We could count the number of sequences by piping again into `wc`!

```{.bash}
head -400 dataOriginal.fastq | grep NNNNN | wc -l
```

&nbsp;

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/pless.json'
display_quiz("./questions/piping.json", shuffle_answers=True, question_alignment="center")
```

---

## Compendium for file manipulation  {.smaller .scrollable}

:::: {.columns}

::: {.column width="50%" }

### List Files and Directories
- `ls`: List files and directories in the current directory.
- `ls -l`: List in long format (detailed information).
- `ls -a`: List all files, including hidden ones (starting with `.`).
- `ls -lh`: List with human-readable file sizes (e.g., KB, MB).
- `ls -R`: Recursively list files in directories and subdirectories.

### Copy Files and Directories
- `cp source_file destination`: Copy a file to a destination.
- `cp file1 file2 dir/`: Copy multiple files to a directory.
- `cp -r dir1 dir2`: Recursively copy a directory and its contents.

### Move (or Rename) Files and Directories
- `mv source_file destination`: Move a file to a new location or rename it.
- `mv file1 file2 dir/`: Move multiple files to a directory.
- `mv oldname newname`: Rename a file or directory.

### Remove Files and Directories
- `rm file`: Remove a file.
- `rm -f file`: Force remove a file (suppress confirmation).
- `rm -r dir`: Recursively remove a directory and its contents.
- `rm -rf dir`: Forcefully and recursively remove a directory and its contents (use with caution).

### Create Directories
- `mkdir dir_name`: Create a new directory.
- `mkdir -p parent_dir/child_dir`: Create a directory with parent directories as needed.

:::

::: {.column width="50%" }

### Change File Permissions
- `chmod 644 file`: Set read/write for owner, and read-only for group and others.
- `chmod 755 file`: Set read/write/execute for owner, and read/execute for group and others.
- `chmod +x file`: Add execute permission to a file.
- `chmod -R 755 dir`: Recursively change permissions for a directory and its contents.

### Change File Ownership
- `chown user file`: Change the ownership of a file.
- `chown user:group file`: Change the owner and group of a file.
- `chown -R user:group dir`: Recursively change ownership of a directory and its contents.

### File Information
- `file filename`: Display the type of a file.
- `stat filename`: Show detailed information about a file (size, permissions, timestamps).
- `du -sh file/dir`: Display the disk usage of a file or directory (in human-readable format).

### Create and View Files
- `touch filename`: Create an empty file or update the timestamp of an existing file.
- `cat filename`: View the contents of a file.
- `less filename`: View the contents of a file, with navigation.
- `head -n 10 filename`: View the first 10 lines of a file.
- `tail -n 10 filename`: View the last 10 lines of a file.

### Links
- `ln file link_name`: Create a hard link.
- `ln -s target link_name`: Create a symbolic (soft) link.

:::

::::

---

## Compendium for `less`  {.smaller .scrollable}

:::: {.columns}

::: {.column width="50%" }

### Basic Navigation
- **Move Forward:**
  - `Space` or `f`: Scroll forward by one page.
  - `Down Arrow` or `j`: Scroll down by one line.
  - `d`: Scroll down by half a page.

- **Move Backward:**
  - `b`: Scroll backward by one page.
  - `Up Arrow` or `k`: Scroll up by one line.
  - `u`: Scroll up by half a page.

- **Go to Specific Line or Position:**
  - `G`: Go to the end of the file.
  - `g`: Go to the beginning of the file.
  - `numberG` or `number%`: Go to a specific line or percentage in the file.

### Searching
- **Search Forward:**
  - `/pattern`: Search forward for a pattern (use `n` to move to the next match).
  
- **Search Backward:**
  - `?pattern`: Search backward for a pattern (use `N` to move to the previous match).

- **Repeat Last Search:**
  - `n`: Repeat the last search in the same direction.
  - `N`: Repeat the last search in the opposite direction.

### Display Line Numbers
- **Show Line Numbers:**
  - `-N` or `--LINE-NUMBERS`: Show line numbers (must start `less` with this option).

### Marking Positions
- **Set a Mark:**
  - `m<letter>`: Mark the current position with a letter.

- **Jump to a Mark:**
  - `'<letter>`: Return to the marked position.

### Exiting
- **Quit `less`:**
  - `q`: Exit `less`.

### Scrolling Long Lines
- **Move Left and Right (For Long Lines):**
  - `Right Arrow` or `→`: Scroll right.
  - `Left Arrow` or `←`: Scroll left.

:::

::: {.column width="50%" }

### File Manipulation
- **Open Another File:**
  - `:e filename`: Open another file while inside `less`.

- **View Multiple Files:**
  - `:n`: Go to the next file (if multiple files were opened).
  - `:p`: Go to the previous file.

### Miscellaneous
- **Follow File in Real Time:**
  - `F`: Continuously view a file as it grows (like `tail -f`).
  
- **Show Current Filename:**
  - `=`: Show the current file name, line number, and percentage through the file.

- **Help Menu:**
  - `h`: Display help with all available commands.

### View Line Numbers Temporarily (without restarting `less`)
- **Toggle Line Numbers:**
  - `-N`: While in a session, use this to toggle line number display.

:::

::::

# Project management

- What are **GDK projects** 
- how to **track the resource usage**, and 
- how to **organize a project**

## GDK projects

:::{.callout-note title="what is a project"}
Projects are contained in `/faststorage/project/`, and are simple folders with some perks:

- you have to **request their creation** to GDK administrators
- **access is limited** to you, and users you invite
- CPU, GPU, storage and backup usage are **registered** under the project for each user
- you can **keep track** of per-project and -user resource usage 
:::

---

![Example of a project managed by `you` with two invited users. `you` has requested the creation of `coolProject` and manages the project. `you` invited two users to the project.](img/projectScheme.png)

---

:::{.callout-warning title="Common-sense in project creation"}
- Do not request a lot of different small project, but make larger/comprehensive ones
    - **No-go example**: 3 projects `bulkRNA_mouse`, `bulkRNA_human`, `bulkRNA_apes` with the same invited users
    - **Good example**: one project `bulkRNA_studies` with subfolders `bulkRNA_mouse`, `bulkRNA_human`, `bulkRNA_apes`.

- Why? **Projects cannot be deleted**, so they keep cumulating
:::

## Creation

Request a project (after login on GDK) with the command

```{.bash}
gdk-project-request -g <project_name>
```

&nbsp;

After GDK approval, a project folder with the desired name appears in `~` and `/faststorage/project`. You should be able to set the WD into that folder:

```{.bash}
cd <project_name>
```

or

```{.bash}
cd ~/<project_name>
```

---

### Users management

**Only the creator** (owner) can see the project folder. You (and only you) can add an user

```{.bash}
gdk-project-add-user -g <project name> -u <username>
```

&nbsp;

or remove it

```{.bash}
gdk-project-remove-user -g <project name> -u <username>
```

---

Users can also be promoted to have administrative rights in the project

```{.bash}
gdk-project-promote-user -g <project name> -u <username>
```

&nbsp;

or demoted from those rights

```{.bash}
gdk-project-demote-user -g <project name> -u <username>
```

---

### Accounting

You can see **globally**  monthly used resources of your projects with

```{.bash}
gdk-project-usage
```

&nbsp;

Example output:

```{.bash .code-overflow-scroll}
project               period  billing hours  storage (TB)  backup (TB)  storage files  backup files
HDSSandbox            2024-8          44.58          0.09         0.00           6024             0
HDSSandbox            2024-9          25.38          0.09         0.00           6025             0
ngssummer2024         2024-6           6.73          0.00         0.00              0             0
ngssummer2024         2024-7        7547.48          0.72         0.00          27479             0
```

---

More detailed usage: by users on a selected project
&nbsp;

You can see how many resources your projects are using with 

```{.bash}
gdk-project-usage -u -p <project-name>
```

&nbsp;

Example output:

```{.bash .code-overflow-scroll}
project               period  billing hours  storage (TB)  backup (TB)  storage files  backup files
ngssummer2024  sarasj             2024-7          77.98          0.02         0.00            528             0
ngssummer2024  sarasj             2024-8           0.00          0.02         0.00            528             0
ngssummer2024  savvasc            2024-7         223.21          0.02         0.00            564             0
ngssummer2024  savvasc            2024-8           0.00          0.02         0.00            564             0
ngssummer2024  simonnn            2024-7         173.29          0.01         0.00            579             0
ngssummer2024  simonnn            2024-8           0.00          0.01         0.00            579             0
```

---

:::{.callout-tip title="Accounting Tips"}
- You can pipe the accounting output into `grep` to isolate specific users and/or months:

```{.bash}
gdk-project-usage -u -p <project-name> | grep <username> | grep <period>
```

&nbsp;

- all the accounting outputs can be saved into a file, which you can later open for example as Excel sheet.

Example:
```{.bash}
gdk-project-usage > accountingGDK.csv
```
:::

---

:::{.callout-tip title="Private files or folders"}
You have a folder or a file into the project which you do not want to share: Use 

```{.bash}
chmod -R go-rwx <file or folder>
```

&nbsp;

which you can revert using

```{.bash}
chmod -R go+rwx <file or folder>
```
:::

## Folders management

Have a coherent folder structure - your future self will thank.

![Example of structure, which backs up raw data and analysis](img/structure.png){width=400px fig-align="center"}

---

If your project has many users, a good structure can be

![](img/multistructure.png){width=400px fig-align="center"}

---

:::{.callout-warning title="MUST-KNOWs for a GDK project" layout-align="center"}
- remove **unused intermediate files**
    - unused and forgotten object filling up storage
- backup **only the established truth** of your analysis
    - in other words the very initial data of your analysis, and the scripts
- **outputs of many files** should be removed or zipped together into one 
    - otherwise GDK indexes all of them: slow!!!

&nbsp;

**Backup cost >>> Storage cost >> Computation cost**
:::

# Downloads and Copies

- Downloads from Internet to GDK
- Uploads from a local PC to GDK
- Downloads from GDK to a local PC
- Transfer data between GDK and another cluster
- Graphical interface for download/upload with GDK

---

Data transfer amongst the web, GDK and your PC is an everyday action which you can easily perform.

:::{.callout-warning}
Downloads should **always** happens on the `front-end` nodes, and **never** using a compute node when working on `GenomeDK`
:::

## Download with wget

`wget` is a utility for **command-line-based downloads**. It is already installed on `GenomeDK` and works with `http`, `https`, `ftp` protocols.

&nbsp;

Example:

```{.bash}
wget -O ./output.png \
     -c \
     -b \
     https://example.com/image.png
```
downloads a `png` file and saves it as `output.png` (option `O`), downloads in background (`-b`) and if the download was interrupted earlier, it retrieves it from where it stopped (`-c`).

---

`wget` has many options you can use, but what shown in the example above is what you need most times. You can see them with the command

```{.bash}
wget --help
```

&nbsp;

Also, you can find [this cheatsheet](https://opensource.com/sites/default/files/gated-content/osdc_cheatsheet-wget-2021.10.21.pdf) useful for remembering the commands to most of the things you can think about downloading files using wget. [At this page](https://opensource.com/article/21/10/linux-wget-command) there are also some concrete examples for `wget`.

## SCP transfer

`SCP` (Secure Copy Protocol) can transfer files securely

- between a LOCAL and a REMOTE host (your PC and GDK)
- between TWO REMOTE hosts (GDK and another cluster)

&nbsp;

You can use it to transfer files **from your pc to GenomeDK and viceversa**, but also **between GenomeDK and another computing cluster** (for example, downloading data from a collaborator, which resides on a different remote computing system).

---

To copy a file **to GenomeDK** from your local computer:
```{.bash}
scp /home/my_laptop/Documents/file.txt \
    username@login.genome.au.dk:/home/username/my_project/
```

&nbsp;

The **inverse operation** just changes the order of the sender and receiver:
```{.bash}
scp username@login.genome.au.dk:/home/username/my_project/file.txt \
    /home/my_laptop/Documents/
```

---

If you want to copy an entire folder, use the option `-r` (recursive copy). The previous examples become

```{.bash}
scp -r /home/my_laptop/Documents/folder \
       username@login.genome.au.dk:/home/username/my_project/
```

&nbsp;

and

```{.bash}
scp -r username@login.genome.au.dk:/home/username/my_project/folder \
       /home/my_laptop/Documents/
```

&nbsp;

A few more options are available and you can see them with the command ``` scp --help ```.

## Rsync transfer {visibility="hidden"}

Differently from `scp`, you can use `rsync` to **syncronize files and folders between two locations**. It copies only the changes in the data and not all of it every time.

&nbsp;

Copying a file or a folder between your computer and `GenomeDK` works exactly as in `scp`. For example

```{.bash}
rsync --partial --progress -r \
      username@login.genome.au.dk:/home/username/my_project/folder \
      /home/my_laptop/Documents/
```

where we add `-progress` to show a progress bar and `--partial` to retrieve interrupted downloads

## Interactive transfer

You can also do transfering with an interactive software, such as `Filezilla`, which  has an easy interface. [Download Filezilla](https://filezilla-project.org/download.php?type=client).

&nbsp;

When done, open `Filezilla` and use the following information on the login bar:

- Host: `login.genome.au.dk`
- Username, Password: your `GenomeDK` username and password
- Port: `22`

---

Press on `Quick Connect`. As a result, you will establish a secure connection to `GenomeDK`. On the left-side browser you can see your local folders and files. On the right-side, the folders and files on `GenomeDK` starting from your `home`.\

![](./img/filezilla1.png){fig-align="center"}

---

If you right-click on any local file or folder, you can **upload** it immediately, or **add it to the transfer queue**. The file will end up in the selected folder of the right-side browser.

![](./img/filezilla2.png){fig-align="center"}

---

The **download** process works similarly using the right-side browser and choosing the destination folder on the left-side browser.

![](./img/filezilla3.png){fig-align="center"}

---

If you have created a queue, this will be shown at the bottom of the window as a list. You can inspect destination folders from there and choose other options such as transfer priority.

![](./img/filezilla4.png){fig-align="center"}

To start a queue, use `CTRL + P`, `Transfer --> Process Queue` or press  the button ![](./img/filezilla5.png){width=100} on the toolbar.


# Running a Job

&nbsp;

Running programs on a computing cluster happens through **jobs**. 

&nbsp;

Learn how to get hold of **computing resources** to run your programs.

## What is a job on a HPC

A computational task **executed on requested HPC resources** (computing nodes), which are handled by the **queueing system** (SLURM).

![](img/Job-on-cluster.png){fig-align="center"}

---


The command `gnodes` will tell you if there is heavy usage across the computing nodes

![Usage of computing nodes. Each node has a name (e.g. cn-1001). The symbols for each node mean running a program (`0`), assigned to an user (`_`) and available (`.`)](./img/gnodes.png)

If you want to venture more into checking the queueing status, Moi has done [a great interactive script](https://github.com/MoiColl/cluster_status) in R Shiny for that.

---

Front-end nodes are limited in memory and power, and **should only be for basic operations** such as

- starting a new project

- small folders and files management

- small software installations

- data transfer

and in general you **should not** use them to run computations. This might slow down all other users on the front-end.

---

## Interactive jobs

Useful to run a **non-repetitive task interactively**

Examples: 

- splitting by chromosome that one `bam` file you just got 

- open `python`/`R` and do some statistics 

- compress/decompress multiple files, maybe in parallel

Once you exit from the job, anything running into it will stop.

---

To run an interactive job simply use the command

```
[fe-open-01]$ srun --mem=<GB_of_RAM>g -c <nr_cores> --time=<days-hrs:mins:secs>  --account=<project_name> --pty /bin/bash
```

For example

```
[fe-open-01]$ srun --mem=32g -c 2 --time=6:0:0  --account=<project_name> --pty /bin/bash
```

The **queueing system** makes you wait based on the resources you ask and how busy the nodes are. When you get **assigned a node**, the resources are available. The node name is **shown in the prompt**.

```
[<username>@s21n32 ~]$
```

## Batch script (sbatch)

Useful to **run a program non-interactively**, usually for longer time and without interaction from the user. A batch script contains 

- the desired **resources**
- the sequence of **commands** to be executed

and

- has a filename **without spaces** (forget spaces from now on)
---

### Example 

A file called `align.sh` such that:

```{.bash}
#!/bin/bash
#SBATCH --account my_project
#SBATCH --cpus-per-task= 8
#SBATCH --mem 16g
#SBATCH --time 04:00:00

#activate environment
eval "$(conda shell.bash hook)"
conda activate bam_tools
#index the reference file
bwa-mem2 index reference/chr2.fa
#align data
bwa-mem2 -t 8 reference/chr2.fa \
             genomes/S_Korean-2.region.fq.gz \
        | samtools sort \
            -@ 7 \
            -n \
            -O BAM \
        > alignment/S_Korean-2.sorted.bam

exit 0
```

---

Send the script to the queueing system:

```{.bash}
sbatch align.sh
```
```
Submitted batch job 33735298
```

&nbsp;

Interrogate SLURM about the specific job

```{.bash}
jobinfo 33735298
```

```
>Name                : align.sh
>User                : samuele
>Account             : my_project
>Partition           : short
>Nodes               : s21n43
>Cores               : 8
>GPUs                : 0
>State               : RUNNING
>...
```

---

or about all the queued jobs

:::: {.columns}

::: {.column width="45%" }
```{.bash}
squeue -u <username>
```
:::
::: {.column width="10%" }
<html><center> or </center></html>
:::
::: {.column width="45%" }
```{.bash}
squeue --me
```
:::
::::


```
>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
>33735928     short align.sh  samuele  R       1:12      1 s21n43
```

&nbsp;

If you change your mind and want to cancel a job:

```{.bash}
scancel 33735928
```

---

:::{.callout-tip}
To observe in real time the output of  the job, refresh the last lines of the log file for that job:

```{.bash}
watch tail align.sh-33735928.out
```
&nbsp;

To look at the whole log (not in real time), run at any time

```{.bash}
less -S align.sh-33735928.out
```

Checking the log files can be useful for debugging, when for example a command gives an error and the job interrupts before its end.
:::


## Choosing the right CPU-RAM

Try to run a job with a smaller dataset as a test. While it is running

- use `squeue --me` and look at the node id

- log into that node from the front-end:
  
  ```{.bash}
  ssh <NODEID>
  ```

---

- use `htop -u <username>` to see what is running and how much memory and CPU it uses
  ![](img/htop.png)

---

:::{.callout-note icon="false" title="exercise (1/4)"}

You have a script which contains two programs: a genome simulator called `genomeSim` 
and a program to infer similarity between the simulated
genomes, called `inferSim`.

You run the script simulating a dataset 100 times smaller than what you would need. Below is what you see using 
`htop -u <username>` (next slide)
:::

---

:::{.callout-note icon="false" title="exercise (2/4)"}

While the simulation is running
```
 PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+   P COMMAND          
 8249 newhall   20   0  153m 4488  472 R   147.1  28.0   0:02.78 6 genomeSim              
 8250 newhall   20   0  153m 4488  472 R   147.2  30.9   0:02.76 2 genomeSim                        
 8243 newhall   20   0  153m 4488  472 R   146.1  45.4   0:02.76 1 genomeSim              
 8239 newhall   20   0  153m 4488  472 S   146.5  37.1   0:02.76 7 genomeSim                   
```

and while the similarity inference is running

```
 PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+   P COMMAND                      
 8236 newhall   20   0  153m 4488  472 R   7.3  0.0   0:12.11 6 inferSimilarity              
 8237 newhall   20   0  153m 4488  472 S   8.1  0.0   0:14.33 4 inferSimilarity             
```

The script is finished in around 60 minutes, where the simulation itself took 50 minutes. 
You asked for 16 cores and 128GB of memory when you sent the script to the `slurm` queueing manager.

:::

---

:::{.callout-note icon="false" title="exercise (3/4)"}

Q1 split

:::

---

:::{.callout-note icon="false" title="exercise (3/4)"}

Q2 Memory for the two jobs

:::

---


:::{.callout-note icon="false" title="exercise (3/4)"}

Q1 split

:::

---

## Other ways of running jobs {.hidden}

Beyond `sbatch`, you can use other tools for workflows which are

- **modular and composable**: sequences of commands can be applied in various contexts, composed together in the desired ordering
- **scalable and parallel** handling many sequences of operations parallelly or interdependently
- **flexible** where repetitive operations can be automatized over multiple applications

Some workflow tools:

- [Snakemake](https://snakemake.readthedocs.io/en/stable/)
- [NextFlow](https://www.nextflow.io/)
- [Gwf](https://gwf.app/)

&nbsp;

`Gwf` has an easy `python` syntax instead of its own language to write workflows.

&nbsp;

Learning a workflow language takes some time commitment, but it is worth the effort.

# Closing the workshop

- More in this slides than what we went through
  - useful commands
  - external material (tutorials at [Cafe](https://abc.au.dk/Documentation) or [genome.au.dk](https://genome.au.dk))

- Updated over time, use as a reference

- Impossible to cover everything at once. We will also advanced/pipeline workshop

- Come to our [Cafe](https://abc.au.dk) and/or ask

- Documentation on [genome.au.dk](https://genome.au.dk)

---

## A taste of the next workshops {.hidden}

- virtual terminals with `tmux`
- git setup
- advanced functionalities
  - `awk` for advanced text file manipulation
  - `rsync` for synchronization of data
- browser-based applications
- launch containers
- gwf pipelines 

## Your input for topics and evaluation {.hidden}

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSevPQOj2FBtmhKp_kcJrWIv3jZQ-8ymvw67B_M_L-5dytiPEw/viewform?embedded=true" width="640" height="1218" frameborder="0" marginheight="0" marginwidth="0">Indlæser…</iframe>
