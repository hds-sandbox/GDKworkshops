---
title: "Advanced GenomeDK"
subtitle: "More-than-basic things to do and tips for GDK, tinyurl.com/advGDK"
author: 
    - "Samuele Soraggi"
    - "Manuel Peral-Vázquez"
    - "Dan Søndergaard"
institute:
    - Health Data Science sandbox, BiRC, AU
    - Molecular Biology and Genetics, AU
    - GenomeDK, Health, AU
date: last-modified
format: 
  revealjs:
    chalkboard: true
toc: false
toc-depth: 1
slide-number: h.v
code-line-numbers: false
logo: img/logos.png
navigation-mode: vertical
smaller: true
---

# Some background

- These slides are both a presentation and a small reference manual

- In many slides you will be doing things - **open your terminals and slides**

- Official reference documentation: [genome.au.dk](https://genome.au.dk)

- Some advanced things require a bit of practice/frustration, but I hope to reduce it

- Most important message before starting any workshop: [RTFM - Read The Field Manual!](https://idratherbewriting.com/2012/08/30/the-blame-game-of-rtfm/). Though
  - Some manuals can be lousy, but the ones for UNIX tools are usually good
  - Unusual options might be buried somewhere or badly explained

## When you need to ask for help

- **Practical help:** 
  
  Samuele (BiRC, MBG) - samuele@birc.au.dk 

- **Drop in hours:**

  - Bioinformatics Cafe: [https://abc.au.dk](abc.au.dk), abcafe@au.dk
  - Samuele (BiRC, MBG) - samuele@birc.au.dk - we just set up a meeting/zoom

- **General mail for assistance**

  support@genome.au.dk

## Program {.scrollable}

- **10:00-10:45**: 
  - Workshop Introduction
  - Frequently used on UNIX
  - Github configuration

- **10:45-11:30**: 
  - `rsync` copy and backups

- **11:30-12:00**: 
  - Web applications, ports and tunnels

- **12:45-13:30**: 
  - Containers (Docker, singularity)

- **13:30-**: 
  - Questions and discussions

## Extras

Documentation you can explore on your own.

- An advanced function to download selected folders from github

- Batch scripts

- Managing multiple terminals on `tmux` 

## Get the slides

Webpage: [https://hds-sandbox.github.io/GDKworkshops/](https://tinyurl.com/gdkSlides)

![Slides will always be up to date in this webpage](./img/webpageGDK.png)

## Navigate the slides

![](./img/slideGuide.png){fig-align="center"}

# Frequently used on UNIX

- Configuration file(s)
- System variables
- Safety settings
- Shortcuts

## Configuration files

Your `~/.bashrc` file contains settings for your user. Those are bash commands which run at every login.

&nbsp;

Common practice for many softwares is to have a configuration file in your home, often starting with `.`, which makes it a hidden file.

&nbsp;

Examples:

- `.emacs` for emacs
- `.gitconfig` for github
- `.condarc` for conda
- `.nanorc` for nano editor

Plus other things like your command history on the terminal (`~/.bash_history`) and your settings (`~/.bashrc`).

## Exercise I: singularity settings

Let's make a useful setting to run at each login. We will need a temporary folder for `singularity` containers (more on those later) when downloaded. Default is your home, which will be filled up in no time (folder `~/.singularity`) with cache material.

&nbsp;

Edit the file `~/.bashrc` (use `nano ~/.bashrc` or any editor you want). Add those lines:

```{.bash}
mkdir -p -m 700 /tmp/$USER
export SINGULARITY_TMPDIR=/tmp/$USER
export SINGULARITY_CACHEDIR=/tmp/$USER
```

&nbsp;

The `-m 700` option for `mkdir` command ensures also **you are the only one which can access the temporary files**. Useful is you use a container with password or sensitive info, so no one can access it (`/tmp/` is a public folder)! 

## Exercise II - aliases {.scrollable}

:::{.callout-warning}
Please run this exercise so that we can use some of the aliases and functions in the rest of the workshop.
:::

Now, there are many repetitive things we do every day. For example:

- remove files and double check we can
- `cd ../` and `cd ../../` and ... and `cd ../../../../../../../`

and every time it is just annoying to waste precious time. Why not creating some aliases for all those deplorably long commands? Choose the aliases you prefere from the list below and add them in your `.bashrc` file:

```{.bash}
## Safe file handling
alias rmi='rm -i'
alias cpi='cp -i'
alias mvi='mv -i'

## Upwards navigation in the File system
alias ..='cd ..'
alias ...='cd ../../../'
alias ....='cd ../../../../'
alias .....='cd ../../../../'

## List views
alias ll='ls -laht' #detailed
alias l='ls -aC' #compressed
```

## Exercise III - functions {.scrollable}

You can also create functions including multiple commands: for example making a directory and then `cd` into it.

:::{.callout-note}
These are just inspirations, you can create any alias and function to avoid repetitive/long commands. Find all repetitive commands you use and wrap it up into the `~/.bashrc` file!
:::

```{.bash}
## make and cd
## make a folder and go into it
mkcd() {
    mkdir -p $1; cd $1
    echo created $1
    }

## interactive job using the same resources of
## an existing job already running
## useful to debug and check resource usage
sshell() {
  srun --jobid $1 --overlap --pty bash
}
```

**Exercise finished** 

## [Optional] Configure github on GenomeDK

Github is a web-based platform for version control and collaboration, built around the Git tool. You can get an account for free at [github.com](https://github.com).

When you use Github on GenomeDK, you can configure your ssh keys to avoid writing your name and password every time you push or pull changes. 

### Create ssh key

On the cluster run 

```{.bash}
ssh-keygen -t ed25519 -C "GithubAccountMail@example.com"
```

When asked, you can choose to name the file. Call it `~/.ssh/id_ed25519_github`. When asked for password, you can leave it empty (press enter).

---

### Add the ssh key to your ssh agent

Add the key to the ssh agent, which manages your keys. Write the following on your `~/.bashrc` file using a text editor:

```{.bash}
# Start ssh-agent for github if not already running
eval "$(ssh-agent -s)" > /dev/null
ssh-add -l &>/dev/null || ssh-add ~/.ssh/id_ed25519_github
```

Now print your public key on the terminal. Copy it because you need to paste it on the github website:

```{.bash}
cat ~/.ssh/id_ed25519_github.pub
```

---

Go on github.com and login. Go to `Settings`, `SSH and GPG keys`, `New SSH key`. Paste the public key you just copied and give it a name recalling it is for usage with GenomeDK.

![](img/sshKeysGithub.png){fig-align="center" width=800px}

---

Now, test your connection to github. First apply the changes from the `~/.bashrc` file.

```{.bash}
source ~/.bashrc
ssh -T git@github.com
```

You should see a welcome message.

:::{.callout-tip}
If you have already cloned a repository using its URL, you might need this command to swith to ssh, so that you use the ssh key. Adapt the following code with your username and repository name:

```{.bash}
git remote set-url origin git@github.com:username/repo.git
```
:::


# Syncronizations of data

- How to copy using `rsync`
- Use `rsync` to create backups and versioning

## transfer and sync with `rsync`

`rsync` is a very versatile tool for

- transfering **from remote to local** host (and viceversa)
- copying from **local to local** host (e.g. data backups/sync) 
- transfering only files which has changed from last copy (**incremental copy**)

:::{.callout-warning}
`rsync` cannot make a transfer between two remote hosts, e.g. running from your PC to transfer data between GenomeDK and Computerome.

`rsync` cannot download from web URLs
:::

Lots of options you can find in the manual (would require a workshop only for that)

<div style="text-align: center; margin-top: 20px;">
  <a href="https://linux.die.net/man/1/rsync" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #007BFF; color: white; text-decoration: none; border-radius: 5px; border: 2px solid #0056b3; font-weight: bold;">
    rsync manual
  </a>
</div>

## Exercise

Log into GenomeDK. Create anywhere you prefere a folder called `advancedGDK` containing
`rsync/data`

```{.bash}
mkcd advancedGDK/rsync/data
```

Create 100 files with extensions `fastq` and `log` in the data folder

```{.bash}
touch data/file{1..100}.fastq data/file{1..100}.log
```

---

### Local-to-local copy

:::{.callout-note}
The syntax of `rsync` is pretty simple:

```
rsync OPTIONS ORIGIN(s) DESTINATION
```
:::

&nbsp;

An archive (incremental) copy can be done with the options `a`. You can add a progress bar with `P`. You can exclude files: here we want only the ones with `fastq` extension. Run the command

```{.bash}
rsync -aP --exclude="*.log" data backup
```

This will copy all the `fastq` files in `backup/data`. You can check with `ls`.

:::{.callout-warning title="Syntax perks"}
Using `data` will copy the entire folder, while `data/` will copy only its content! This is common to many other UNIX tools.
:::

---

Change the first ten `fastq` files with some text:

```{.bash}
for i in {1..10}; do echo hello >> data/file$i.fastq; done
```

Now, we do not only want to do an incremental copy of those file with `rsync`, but also keep the previous version of those files. We create a folder to backup those, naming it with date and time (you will find it in your `backup` directory):

```{.bash}
rsync -aP --exclude="*.log" \
      --backup \
      --backup-dir=versioning_$(date +%F_%T)/ \
      data \
      backup
```

:::{.callout-tip}
If you create a folder called `backup` in your project folder, you can use versioning to backup your analysis and results incrementally on the cluster's backup system. Keep an eye on the space used!
:::

**Exercise finished**

---

### Transfer between local and remote

You can in the same way transfer and backup data between your local host (your PC, or GenomeDK) and another remote host (another cluster). You need Linux or Mac on the local host.
For example, to get on your computer the same `fastq` files:

```{.bash}
rsync -aP --exclude="*.log" USERNAME@login.genome.au.dk:PATH_TO/advancedGDK/data PATH_TO/backup
```

The opposite can be done uploading data from your computer. For example:

```{.bash}
rsync -aP --exclude="*.log" PATH_TO/data USERNAME@login.genome.au.dk:PATH_TO/backup
```

&nbsp;

:::{.callout-warning title="Avoid a typical error"}
To transfer from GenomeDK to your computer, and viceversa, you need to use the commands above **from your local computer**, and NOT when you are logged into GenomeDK!
:::

# Web applications, ports, tunneling

## Web applications

&nbsp;

Why do we use web applications for graphical interfaces?

&nbsp;

- all the graphics heavy-lifting is done by the browser
- before, the X11 forwarding was the way to do graphics from remote
- problem: X11 sends the whole graphics over the network, which is slow
- on the interactive desktop, rstudio runs using VNC (better than X11)

---

A web application on GenomeDK:

- starts a **server process** on the cluster
- This server listens for incoming requests on a specific **port**
- The server sends and receives data over the network via the port.

&nbsp;

The local user:

- creates a **tunnel**, which is an `ssh` connection mapping to the remote port used by the server process

---

![How the port forwarding looks like from the local user (your pc) to the remote node of the cluster. The purple command has to be launched on the local computer, once the server is running on the remote host. Source: KU Leuven.](img/sshPortForwarding.png){fig-align="center" width=800px}

---

### Which port to use

- Each server process on a machine needs a **unique port** (p2 on previous figure) to avoid conflicts.

- Ports are in common between users on GenomeDK. So you can only use the port corresponding to your user number, which you can see with
  
  `echo $UID`

- You will see all this in the next exercise

:::{.callout-warning title="better safe than sorry"}
Launch a web application which has tokens (a random code in the URL for the browser) or a password you can setup. In theory, anyone on your same node of the cluster can get into your server process and see your program and data!
:::

## Exercise: jupyterlab web server{.scrollable}

If you DO NOT have the `conda` package manager, you can quickly install it from the box below, otherwise move to the next slide!

:::{.callout-tip title="Install conda" collapse="true"}
Run the installation script to install the software. There are some informative messages during the installation. You might need to say `yes` a few times

```{.bash}
wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O miniforge.sh
chmod +x miniforge.sh
bash miniforge.sh -b
~/miniforge3/bin/conda init bash
source ~/.bashrc
```

When you are done, you need a little bit of configuration. You can run the following command to configure `conda` (run them only once, they are not needed again):

```{.bash}
conda config --append channels conda-forge
conda config --append channels bioconda
conda config --set channel_priority strict
conda config --set auto_activate_base false
source ~/.bashrc
```

Now you are ready to move on!
:::

---

Create a new `conda` environment:

```{.bash}
conda create -y -n GDKjupyter jupyterlab numpy pandas
```

&nbsp;

Start a job with just a few resources.

```{.bash}
srun --mem=4g --cores=1 --time=4:00:0 --pty /bin/bash
```

&nbsp;

Now activate your environment and run jupyterlab. The node name (remote host) and your user ID (for the port number) **are given as variables** to the web server simply using `$(hostname)` and `$UID`:

```{.bash}
conda activate GDKjupyter
jupyter-lab --port=$UID --ip=$(hostname)
```

---

You will see some messages and recognize an address with: your node and your user ID. Below it, the URL you can use in your browser, which always starts with the node name. It will look like this, but in your case it might have a longer URL with a random *token* (mine is instead password protected):

![](img/jupyterUrl.png){fig-align="center" width=800px}

&nbsp;

Write down your node number and user id you got from jupyterlab.

**We now need a tunnel** from the local host (your PC)! Write in a new terminal **(not logged into GenomeDK)** a command like the following (matching the example figure above), substituting the correct values:

```{.bash}
ssh -L6835:s21n34:6835 USERNAME@login.genome.au.dk
```

&nbsp;

Your tunnel is now opened. The web application can be accessed **from your browser** at the address given by the server process on GenomeDK, which starts with `127.0.0.1/PORT_NUMBER` (put your correct port number). Copy and paste it in your browser.

**Exercise finished**

---

:::{.callout-tip}
The same logic applies to all other web applications. They will have similar options to define the remote node and port. 

Usually the host node option changes name between `ip`, `host`, `address`, or `hostname`.

&nbsp;

Note also that you will always have to use the address `127.0.0.1/PORT_NUMBER` on your browser when you do the tunneling. Instead you will need to use the address with the node name if you are using the virtual desktop on GenomeDK.
:::

# Containers

:::{.callout-note title="What is a container"}
**Container = ** Standalone and portable software package including 

- code 
- runtime
- libraries
- system tools
- operating system-level dependencies
:::

&nbsp;

Deployment of a container on different HPCs and PCs is reproducible. A virtual environment (conda, mamba, pixi, cargo, npm, ...) depends instead on the host system and is not necessarily fully reproducible on two different computer hardwares.

## Container vs virtual env vs VM

A **virtual environment** isolates dependencies for a specific programming language within the same operating system. It does not include the operating system or system-level dependencies, so it depends on the hosting system.

![](img/containerVSconda.png){fig-align="center" width="600px"}

---

- A **virtual machine (VM)** virtualizes an entire operating system, including the kernel, and runs on a hypervisor (assigns resources to the VM).

![](img/dockerAndVM.gif){fig-align="center" width="600px"}

## Scope of containers

- Containers are usually thought as packing a specific application which can run anywhere (or, which is portable).

- E.g. annoying bioinformatics software requiring specific libraries or long installations.

- Many containers are done with *Docker*, but this is not installed on GenomeDK

- GenomeDK has *Singularity*, which can also run programs installed in Docker containers.

- Very practical to **pull and use** containers **in workflows**.

## Where to find containers?

Typical repositories with pre-built containers are:

- **[Biocontainers](https://biocontainers.pro)**: community-driven initiative to containerize bioinf softwares.
  - x10K tools x100K+ containers
  - [bioconda package index](https://bioconda.github.io/conda-package_index.html) lists all software versions
  - the [Registry page](https://biocontainers.pro/registry) has a searchable interface to find what you need

- **[DockerHub](https://hub.docker.com/)** registry: Public hub for Docker images, often including official containers from software developers

- **[Quay](https://quay.io/)**: Same philosophy of DockerHub.

Once you find a container on the websites, simply use (eventually adapt) the provided code to pull it locally.

## Exercise I: a simple bioinformatics container

We use *biocontainers* to pull containers and recreate a little bulkRNA alignment.

&nbsp;

Make a folder called `containers101` in the `advancedGDK` directory.

```{.bash}
mkdir -p advancedGDK/containers101
cd advancedGDK/containers101
```

&nbsp;

Find a bash bioinformatics software you know on the [Biocontainer Registry](https://biocontainers.pro/registry) and open it to see a detailed description - if you have no good ideas look for the `minimap2` aligner. You should see a software documentation illustrating how to run the software in various ways - see next slide for a screenshot.

---

![Example: Biocontainers page for the `minimap2` splice-aware aligner. Click on the image to enlarge.](img/minimap2Biocontainers.png){fig-align="center" width=100% .lightbox}


---

The page will suggest to run immediately the container with `singularity`. I would suggest downloading it first (`pull` instead of `run`) and then running it.

In the case of `minimap2`:

```{.bash}
singularity pull minimap2.sif https://depot.galaxyproject.org/singularity/minimap2:2.28--h577a1d6_4
```

which creates a container file in your current directory, and calls it `minimap2.sif` (better name than the default `minimap2:2.28--h577a1d6_4`).

&nbsp;

You can either `run` the container, which opens a CLI into it, where you can execute the program. A non-interactive way (useful for pipelines) is to write the command directly. For example:

:::: {.columns}
::: {.column width="50%" }
This will operate the command line inside the container. Here you can then run `minimap2`.
```{.bash}
singularity run minimap2.sif
```
:::
::: {.column width="50%" }
This will immediately run `minimap2` from the container - useful for a pipeline where you do not need any interaction with the command line.
```{.bash}
singularity run minimap2.sif minimap2
```
:::
::::

## Exercise II: options for singularity

Some containers are very easy to run. Some others need a lot of extra options, such as binding specific folders to a path, providing certificates, initializing environmental variables. A small example below:

### Environment variables


The option `--env` can be used to define environment variables, either needed by your software, or useful to write the code to be executed.

```{.bash}
 singularity pull samtools.sif https://depot.galaxyproject.org/singularity/samtools:1.21--h96c455f_1

 singularity run --env REF_PATH=$(pwd) \
                 --env BAM_PREFIX=test01 \
                 samtools.sif \
                 samtools view \
                 -h https://github.com/roryk/tiny-test-data/raw/refs/heads/master/wgs/mt.sorted.bam \
                 -O bam > test01.bam
```

**Ups, it does not work! Can you think of why?** Hint: note that the address for the download of data begins with `https`.

---

### Certificates and binding

:::{.callout-tip title="Why the previous slide didn't work!!!"}
**HTTPS** is a protocol for secure communication over the internet. When you access an URL starting with `https`, your system checks the server's SSL/TLS certificate to ensure it is issued by a trusted Certificate Authority (CA).
Why? To prevent [man-in-the-middle (MITM)](https://www.ibm.com/think/topics/man-in-the-middle) attacks, where an attacker eavesdrops in the data transfer.
:::

The option `--bind` can be used to make your folders available in a specific path for the container. Here, we bind two folders containing the certificates for GDK. Those paths are quite standard across UNIX systems.


```{.bash}
singularity run --env REF_PATH=$(pwd) \
                --env BAM_PREFIX=test01 \
                --bind /etc/ssl/certs:/etc/ssl/certs \
                --bind /etc/pki/ca-trust:/etc/pki/ca-trust \
                samtools.sif \
                samtools view \
                -h https://github.com/roryk/tiny-test-data/raw/refs/heads/master/wgs/mt.sorted.bam \
                -O bam > $BAM_PREFIX.bam
```

**Exercise finished**

---

### Building containers

If you want to build containers with Docker, you need to 

  - build locally, and then upload the container to a repository (DockerHub or Quay). 
  - pull them on GenomeDK with singularity

&nbsp;

The same holds for singularity, because you need root privileges to build a container on the cluster, which you do not have.

## Other options for singularity {.scrollable}

A few other options which can be used in singularity. When you need those really depends on the application:

- `--fakeroot`: Allows running the container with root privileges in a user namespace. Useful for containers that require root access without needing actual root privileges.

- `--writable`: Enables writing to the container image. This is useful for making changes to the container, but it requires the container to be writable. `--writable-tmpfs` to avoid changes to be persistent in a non-writable container.

- `--contain`: Isolates the container from the host system by limiting access to the host's filesystem.

- `--no-home`: Prevents the container from automatically binding the user's home directory. Avoids exposing your home directory to the container.

- `--cleanenv`: Clears all environment variables except those explicitly set for the container.

- `--nv`: Enables NVIDIA GPU support by binding the necessary libraries and drivers. Equivalent for AMD GPUs is `--rocm` (not the case on GDK).

- `--pwd`: Sets the working directory inside the container. 


# Closing the workshop

Please fill out this form :)

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSfImYVZLrmBG_Z54sy1Au_jRwneg4Pjnenh36J34x9SYttSoQ/viewform?embedded=true" width="640" height="640" frameborder="0" marginheight="0" marginwidth="0">Indlæser…</iframe>

---

- A lot of things we could not cover

- use the official documentation! 

- ask for help, use drop in hours ([ABC cafe](https://abc.au.dk))

- try out stuff and google yourself out of small problems
  
- Slides updated over time, use as a reference

- Next workshop all about pipelines

# Extras

Things that are more advanced or are not treated in the workshop, but you might find useful.

## A more advanced bash function for github {.scrollable}

Here a more advanced bash function you can paste into your `~/.bashrc` file.
Why not making one for `git clone` downloading only the latest commit history and choosing specific folders for the repository?

```{.bash}
# Git clone with depth 1 and choice of folders
#   arg 1: username/repository
#   arg 2: folders and files in quotes '', backspace separator
#   arg 3: local download folder name (optional, default:repo)
#   arg 4: branch (optional, default:main)
# Examples:
#   ghdir github/gitignore 'community Global' test01 main
#   ghdir github/gitignore 'community Global' 
ghdir() {
        echo Downloading from $1 in folder $3
        echo Selecting $2
        if [ -z "$4" ]; then
          BRANCH="-b main"
        else
          BRANCH="-b $4"
        fi
        git clone --no-checkout $BRANCH --filter=blob:none --depth 1 https://github.com/$1.git $3
        if [ -z "$3" ]; then
          folder=$(echo "$1" | cut -d'/' -f2)
          cd "$folder"
        else
          cd "$3"
        fi
        git sparse-checkout init --cone
        git sparse-checkout set $2
        git checkout
    }
```


## Batch script (sbatch)

Useful to **run a program non-interactively**, usually for longer time and without interaction from the user. A batch script contains 

- the desired **resources**
- the sequence of **commands** to be executed

and

- has a filename **without spaces** (forget spaces from now on)

---

## Exercise: batch script

Create in Rstudio or Jupyterlab a file called `align.sh` (in the folder `GDKintro`) like below:

```{.bash}

#!/bin/bash
#SBATCH --account PROJECT_NAME
#SBATCH --cpus-per-task=8
#SBATCH --mem 16g
#SBATCH --time 04:00:00

pixi run bwa-mem2 index ref.fasta.gz
#align data
pixi run bwa-mem2 mem -t 8 ref.fasta.gz \
             data.fastq \
            | samtools sort \
            -@ 7 \
            -n \
            -O BAM \
        > data.bam

exit 0
```

---

In the terminal, you need to install two new packages

```{.bash}
pixi add bwa-mem2 samtools
```

and download a reference genome

```{.bash}
wget http://genomedata.org/rnaseq-tutorial/fasta/GRCh38/chr22_with_ERCC92.fa -O ref.fasta.gz
```

Send the script to the queueing system using the terminal:

```{.bash}
sbatch align.sh
```
---

Interrogate SLURM about the specific job with the provided number. For example

```{.bash}
jobinfo 33735298
```

```
>Name                : align.sh
>User                : samuele
>Account             : my_project
>Partition           : short
>Nodes               : s21n43
>Cores               : 8
>GPUs                : 0
>State               : RUNNING
>...
```

---

or about all the queued jobs

:::: {.columns}

::: {.column width="45%" }
```{.bash}
squeue -u USERNAME
```
:::
::: {.column width="10%" }
<html><center> or </center></html>
:::
::: {.column width="45%" }
```{.bash}
squeue --me
```
:::
::::


```
>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
>33735928     short align.sh  samuele  R       1:12      1 s21n43
```

&nbsp;

If you change your mind and want to cancel a job:

```{.bash}
scancel 33735928
```


## Choosing the right CPU-RAM

Try to run a job with a smaller dataset as a test. Or run one of many jobs of the same type.
 While the job is running

- use `squeue --me` and **look at the job id**

- **log into the job** from the front-end terminal using an interactive session:
  
  ```{.bash}
  srun --jobid <job id> --overlap --pty bash
  ```

:::{.callout-warning}
The command above only works if your job is still running! Otherwise it is finished, has failed or is still in queue.
:::

---

- use `htop -u <username>` to see what is running and how much memory and CPU it uses
  ![](img/htop.png)


## Manage multiple terminals with `tmux`

`tmux` is a server application managing multiple terminal sessions. It can 

- start a server with multiple **sessions**
- each session containing one or more **windows with multiple terminals (panes)**
- each terminal run simultaneously and be accessed **(attached)** or exited from **(detached)**
- the tmux server keeps runninng **without a logged user**


![](img/tmux-server.png){fig-align="center" width=400px}

---

## Exercise

`tmux` is a keyboard-only software. But you can set it up also to change windows and panes with the mouse. Simply run this command (**only once**) to enable mouse usage:

```{.bash}
echo "set -g mouse" >> ~/.tmux.conf
```

:::{.callout-warning}
Using the mouse can create problems in some terminal programs, where copy-paste starts acting weird, e.g. on Mac computers and on Windows' Moba XTerm software. In case you have a bad experience, remove the mouse setup from the file `~/.tmux.conf`
:::

&nbsp;

You can start a `tmux` session anywhere. It is easier to navigate sessions giving them a name.
For example start a session called `example1`:

```{.bash}
tmux new -s example1
```

---

The command will set you into the session automatically. The window looks something like below:

![](img/tmuxSession.png){fig-align="center" width=600px}

---

Now, you are in session `example1` and have one window, which you are using now. You can split the window in multiple terminals. Try both those combinations of buttons:

&nbsp;

```
Ctrl + b    %

Ctrl + b    ""
```

&nbsp;

Or keep right-clicked with the mouse to choose the split.

Do split the window horizontally and vertically, running 3 terminals. You can select any of them with the mouse (left-click).

Try to select a window and resize it: while keeping `Ctrl + b` pressed, use the arrows to change the size

---

Now, you have your three panes running in a window.

Create a new window with `Ctrl + b   c`. Or keep right-clicked on the window bar and create a new window.

&nbsp;

You should see another window added in the bottom window bar. Again, switch between windows with your mouse (left-click!)

In the new window, let's look at which tmux sessions and windows are open. Run

```{.bash}
tmux ls
```

&nbsp;

The output will tell you that session `example1` is in use (attached) and has 2 windows. Something like this:

```
example1: 2 windows (created Wed Apr  2 16:12:54 2025) (attached)
```

---

### Launching separate downloads at the same time
Start a new session without attaching to it (`d` option), and call it `downloads`:

```{.bash}
tmux new-session -d -s downloads
```

verify the session is there with `tmux ls`.

:::{.callout-warning}
If you want a new session attaching to it, you need to detach from the current session with `Ctrl + b + d`.
:::

Create a text file with few example files for this workshop to be downloaded.

```{.bash}
curl -s https://api.github.com/repos/hds-sandbox/GDKworkshops/contents/Examples/rsync | jq -r '.[] | .download_url' > downloads.txt
```

---

Now, the script below launches all the URLs from the list in the download session in a new window. The new window closes after the download. If there are less than K downloads active, a new one starts, until the end! You can use this and close your terminal. The downloads will keep going and the window names will be shown to keep an eye on the current downloads. Try it out and use it whenever you have massive number of file downloads.

```{.bash}
mkdir -p downloaded
K=2  # Maximum number of concurrent downloads
while read -r url; do
    # Wait until the number of active tmux windows in the "downloads" session is less than K
    while [ "$(tmux list-windows -t downloads | wc -l)" -ge "$((K+1))" ]; do     
        sleep 1
    done

    # Extract the filename from the URL
    filename=$(basename "$url")

    # Start a new tmux window for the download
    tmux new-window -t downloads -n "$filename" "wget -c $url -O downloaded/$filename && tmux kill-window"
    tmux list-windows -t downloads -F "#{window_name}"   
done < downloads.txt
```

**Exercise finished**