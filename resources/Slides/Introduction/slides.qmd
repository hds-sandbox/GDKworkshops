---
title: "Use GenomeDK"
subtitle: "An introduction to the GDK system and basic commands https://hds-sandbox.github.io/GDKworkshops"
author: 
    - "Samuele Soraggi"
    - "Dan SÃ¸ndergaard"
institute:
    - Health Data Science sandbox, BiRC
    - GenomeDK, Health
date: last-modified
format: 
  revealjs:
    chalkboard: true
toc: true
toc-depth: 1
slide-number: h.v
code-line-numbers: false
logo: img/logos.png
navigation-mode: vertical
---

# GenomeDK's ABC

Learn your way around the basics of the `GenomeDK` cluster.

## Infrastructure

`GenomeDK` is a **computing cluster**, i.e. a set of interconnected computers (nodes). `GenomeDK` has:

- **computing nodes** used for running programs (~15000 cores)
- **storage nodes** storing data in many hard drives (~23 PiB)
- a **network** making nodes talk to each other
- a **frontend** node from which you can send your programs to a node to be executed
- a **queueing system** called *slurm* to prioritize the users' program to be run

---

![](./img/Main-components-of-a-computer-cluster.png){fig-align="center"}

## Access

- **Creating an account** happens through [this form](https://console.genome.au.dk/user-requests/create/) at genome.au.dk

    ![](img/account.png){width=600px fig-alig="center"}

---

- **Logging into GenomeDK** happens through the command ^[both in Linux/Mac terminal and Windows Powershell. Powershell might require `ssh.exe` instead of `ssh`]

    ```{.bash}
    [local]$  ssh USERNAME@login.genome.au.dk
    ```

- When first logged in, **setup the 2-factor authentication** by 
    - showing a QR-code with the command

        ```{.bash}
        [gdk]$  gdk-auth-show-qr
        ```
    - scanning it with your phone's Authenticator app ^[e.g. Microsoft Authenticator, Google Authenticator, ...].


## Access without password

It is nice to avoid writing the password at every access. If you are on the cluster, exit from it to go back to your local computer

```{.bash}
[gdk]$  exit
```

&nbsp;

Now we set up a public-key authentication. We generate a key pair (public and private):

```{.bash}
[local]$  ssh-keygen -t ed25519
```

Always press <kbd>Enter</kbd> and do not insert any password when asked. 

---

and create a folder on the cluster called `.ssh` to contain the public key

```{.bash}
[local]$  ssh <USERNAME>@login.genome.au.dk mkdir -p .ssh
```
&nbsp;

and finally send the public key to the cluster, into the file `authorized_keys`

```{.bash}
[local]$  cat ~/.ssh/id_rsa.pub | ssh username@login.genome.au.dk 'cat >> .ssh/authorized_keys'
```
&nbsp;

After this, your local private key will be tested against GenomeDK's public key every time you log in, without you needing to write a password.

# File System (FS) on GenomeDK

- Directory structure
- Absolute and Relative Paths
- important folders
- navigate the FS on the command line

## How the FS is organized

:::: {.columns}

::: {.column width="60%" }

Folders and files follow a tree-like structure

- `/` is the root folder of the filesystem - nothing is above that
- the FS is shared across all machines and available to all users 
- `home` and `faststorage` are two of the folders in the root
- projects are in `faststorage` and **linked** to your home

:::

::: {.column width="40%"}

![](img/complexTree.png){fig-align="center" width=350px}

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

![](img/complexTree.png){fig-align="center"}

:::
::: {.column width="70%" }

- you can reach files and folders with a **path**

- Examples:
  ```
  /home/username/coolProject/code/analysis.R

  /faststorage/project
  ```

- Paths starting from the root are called **absolute**

:::


::::



---

Look at the File system tree and answer to the following questions:

:::: {.columns}
::: {.column width="40%" }
![](img/complexTree.png){}
:::
::: {.column width="60%" }
```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/paths.json'
display_quiz("./questions/paths.json", shuffle_answers=True, question_alignment="left")
```
:::
::::
---

### Home directory ~ and relative paths

&nbsp;

First of all, log into the cluster

```{.bash}
[local] ssh username@login.genome.au.dk
```

&nbsp;

:::{.callout-tip}
Use the **arrow up key** on the terminal to find the commands you used previously, and press enter when you find the login command
:::

---

After log in, you will find yourself into your private **home folder**, denoted by `~` or equivalently `/home/username/`. Your prompt will look like this:

&nbsp;

```{.bash}
[username@node ~] 
```
which follows the format **[username@node current_folder]**.

&nbsp;

:::{.callout-warning}
- Do not fill up your home folder with data. It has a **limited amount of storage** (a quota of 100GB).
- Your home folder is only private to you
:::

---

### Working directory

The folder in which *you are located* is called **working directory (WD)**. The WD is usually shown in your prompt. Use the following command to see the WD path starting from the root:

```{.bash}
pwd
```

&nbsp;

Every command you run **refers to your WD**. Execute


```{.bash}
ls
```

&nbsp;

and you will see the **list of files and folders** in your WD.

---

### Populating with files and folders

Try to create an empty file now with


```{.bash}
touch emptyFile.txt
```

&nbsp;

and **create a folder**, which will be inside the WD:


```{.bash}
mkdir myFolder
```

&nbsp;

If you use again the `ls` command, the new file and folder will show in the WD.

---

How do you see the directory tree of the WD? Try `tree` with only 2 sublevels of depth:

```{.bash}
tree -L 2 .
```

&nbsp;

:::{.callout-note}
`.` denotes the WD, and is the default when you do not specify it. Retry the command above using `..` (one directory above in the file system) instead of `.`
:::

---

We want to get a file from the internet to the folder `myFolder`. We can use `wget`:

&nbsp;

```{.bash}
wget https://github.com/hartwigmedical/testdata/raw/master/100k_reads_hiseq/TESTX/TESTX_H7YRLADXX_S1_L001_R1_001.fastq.gz\
     -O ./myFolder/data.fastq.gz
```

&nbsp;

:::{.callout-note title="options and manuals"}
`-O` is the option to give a path and name for the downloaded file.

Most commands have a help function to know the *syntax* and *options*. For example you can use `wget --help` and `man wget`.
:::

---

### A bit more on absolute and relative path

:::{.callout-note title="Reminder about the path types"}
The path to a file/folder can be:

- **absolute**: start from the root
- **relative**: starts from the WD (the WD is the new root)
:::

&nbsp;

To look inside `myFolder`, we can both write

:::: {.columns}

::: {.column width="50%" }
```{.bash}

ls myFolder/

```
:::
::: {.column width="50%" }


```{.bash}

ls ~/myFolder/

```
:::
::::

---

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/paths.json'
display_quiz("./questions/whyWD.json", shuffle_answers=True, question_alignment="left")
```

:::{.callout-tip title="The WD is everywhere"}
The working directory is a very useful concept, not limited to Linux/GenomeDK, but used very widely in computer applications.

For example, when you work in `R` or `Python`, there is a default WD which you can change.
:::

---

### Changing WD

Changing WD can be useful. To set the WD inside `myFolder` use

```{.bash}

cd myFolder

```
&nbsp;

and verify with `pwd` the new working directory path. 

---

# Working with Files

Moving, Downloading, Manipulating and other basic operation on files.

## File formats

Many files you use in bioinformatics are nothing else than text files which are written in a specific matter. This specific way of arranging the text in the files gives you many of the **file formats** you encounter when doing bioinformatics. 

&nbsp;

:::{.callout-note}
Some file formats are encoded differently than with plain ASCII text, and cannot usually be seen with a text editor.
:::

---

:::: {.columns}
::: {.column width="50%" }
![A text file is human-readable with any text reader or editor, and is composed of only ASCII characters, such as in the `fastq` file format](img/textfile.png)
:::
::: {.column width="50%" }
![A binary file containes other than ASCII characters. For example, the `bam` file format is binary and can be read with the `samtools` software.](img/binaryFile.png)
:::
::::

---



Let's get ready. Be sure you are in `myFolder` (use `pwd`) - Otherwise use 
```{.bash}
cd ~/myFolder
```

&nbsp;

Now, you can decompress the file `data.fastq.gz`, which is in `gz` compressed format:

```{.bash}
gunzip data.fastq.gz
```

:::{.callout-tip}
For compressing a file into `gz` format, you can use `gzip`. For compressing and decompressing in `zip` format, you have also the commands `zip` and `unzip`.
:::

---

## Less for reading files

`less` is perfect for reading text files: you can scroll with the arrows, and quit pressing `q`. Try

```{.bash}

less data.fastq

```

&nbsp;
The very first sequence you see should be

```
@HISEQ_HU01:89:H7YRLADXX:1:1101:1116:2123 1:N:0:ATCACG
TCTGTGTAAATTACCCAGCCTCACGTATTCCTTTAGAGCAATGCAAAACAGACTAGACAAAAGGCTTTTAAAAGTCTA
ATCTGAGATTCCTGACCAAATGT
+
CCCFFFFFHHHHHJJJJJJJJJJJJHIJJJJJJJJJIJJJJJJJJJJJJJJJJJJJHIJGHJIJJIJJJJJHHHHHHH
FFFFFFFEDDEEEEDDDDDDDDD
```

The first line is metadata, the second is the sequence, then you have an empty line (symbol +), and the quality scores (encoded by letters as in [this table](https://learn.gencore.bio.nyu.edu/ngs-file-formats/quality-scores/)).

---


:::{.callout-tip title="Exercise" icon=false}
Search online (or with `less --help)` how to look for a specific word in a file with `less`. Then visualize the data with `less`, and try to find if there is any sequence of ten adjacent `N`s (which is, ten missing nucleotides). Then, answer the question below 

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/less.json'
display_quiz("./questions/less.json", shuffle_answers=True, question_alignment="center")
```
:::

---

## Counting

How many lines are there in your file? The command `wc` can show that to you:

```{.bash}
wc -l data.fastq
```

&nbsp;


The file has 100000 lines, or 25000 sequences (each sequence is defined by 4 lines). 

&nbsp;

:::{.callout-tip}
`wc` has many functionalities. As always, look for the manual or examples to see how you can use it in other many ways.
:::

---

## Copy and Move

`cp` can copy one or more files - we use it on our data:

```{.bash}
cp data.fastq dataCopy.fastq
```

&nbsp;

`mv` moves a file into another folder - here we move it into our WD, which simply changes its filename:

```{.bash}
mv data.fastq ./dataOriginal.fastq
```

---

Use now `ls -lah` and you will see  two files of identical size and different creation dates. 

&nbsp;

But... are those files identical? `diff` can tell you by printing differences (or nothing if files are identical)

```{.bash}
diff dataOriginal.fastq dataCopy.fastq
```

---

## Writing on a file

Write something on a file using `>`:

```{.bash}
head -4 dataOriginal.fastq > smallFile.fastq
```

&nbsp;

prints out the first four lines of the data into `smallFile.fastq`.

&nbsp;

:::{.callout-warning}

Using again `>` will **overwrite** the file!

:::


---

Print out on the screen:

```{.bash}
cat smallFile.fastq
```

&nbsp;

Avoid overwriting by appending with `>>`:

```{.bash}
tail -4 dataOriginal.fastq >> smallFile.fastq
```

appends the last 4 lines of the data to `smallFile.fastq`. Check again using `cat` or `wc -l`.  

---

## Piping


You can create **small pipelines** directly on the shell with the symbol `|`. The output of a command and send it to the next command when you have `|` ion between. For example, 

```{.bash}
grep NNNNN dataOriginal.fastq
```

find the pattern `NNNNN` in the data.

How to find it in the first hundred sequences? Easy! we **pipe* `head` into *grep*:

```{.bash}
head -400 dataOriginal.fastq | grep NNNNN
```

---


The output of that pipe was a small output on screen - but **outputs can be huge**! We could count the number of sequences by piping again into `wc`!

```{.bash}
head -400 dataOriginal.fastq | grep NNNNN | wc -l
```

&nbsp;

```{python}
#| echo: false
from jupyterquiz import display_quiz
#git_url='https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/webpage-quarto/resources/Slides/Introduction/questions/less.json'
display_quiz("./questions/less.json", shuffle_answers=True, question_alignment="center")
```

# Project management

- What are **GDK projects** 
- how to **manage the resource usage**, and 
- how to **organize a project**

---

## GDK projects

:::{.callout-note title="what is a project"}
Projects are contained in `/faststorage/project/`, and are simple folders with some perks:

- you have to **request their creation** to GDK administrators
- **access is limited** to you, and users you invite
- CPU, GPU, storage and backup usage are **registered** under the project for each user
- you can **keep track** of per-project and -user resource usage 
:::

---

![Example of a project managed by `you` with two invited users. `you` has requested the creation of `coolProject` and manages the project. 'you' invited two users to the project.](img/projectScheme.png)

---

:::{.callout-warning title="Common-sense in project creation"}
- Do not request a lot of different small project, but make larger/comprehensive ones
    - **No-go example**: 3 projects `bulkRNA_mouse`, `bulkRNA_human`, `bulkRNA_apes` with the same invited users
    - **Good example**: one project `bulkRNA_studies` with subfolders `bulkRNA_mouse`, `bulkRNA_human`, `bulkRNA_apes`.

- Why? **Projects cannot be deleted**, so they keep cumulating
:::

---

## Creation

Request a project (after login on GDK) with the command

```{.bash}
gdk-project-request -g <project_name>
```

&nbsp;

After GDK approval, a project folder with the desired name appears in `~` and `/faststorage/project`. You should be able to set the WD into that folder:

```{.bash}
cd <project_name>
```

or

```{.bash}
cd ~/<project_name>
```

---

### Users management

**Only the creator** (owner) can see the project folder. You (and only you) can add an user

```{.bash}
gdk-project-add-user -g <project name> -u <username>
```

&nbsp;

or remove it

```{.bash}
gdk-project-remove-user -g <project name> -u <username>
```

---

Users can also be promoted to have administrative rights in the project

```{.bash}
gdk-project-promote-user -g <project name> -u <username>
```

&nbsp;

or demoted from those rights

```{.bash}
gdk-project-demote-user -g <project name> -u <username>
```

---

### Accounting

You can see **globally**  monthly used resources of your projects with

```{.bash}
gdk-project-usage
```

&nbsp;

Example output:

```{.bash .code-overflow-scroll}
project               period  billing hours  storage (TB)  backup (TB)  storage files  backup files
HDSSandbox            2024-8          44.58          0.09         0.00           6024             0
HDSSandbox            2024-9          25.38          0.09         0.00           6025             0
ngssummer2024         2024-6           6.73          0.00         0.00              0             0
ngssummer2024         2024-7        7547.48          0.72         0.00          27479             0
```

---

More detailed usage: by users on a selected project
&nbsp;

You can see how many resources your projects are using with 

```{.bash}
gdk-project-usage -u -p <project-name>
```

&nbsp;

Example output:

```{.bash .code-overflow-scroll}
project               period  billing hours  storage (TB)  backup (TB)  storage files  backup files
ngssummer2024  sarasj             2024-7          77.98          0.02         0.00            528             0
ngssummer2024  sarasj             2024-8           0.00          0.02         0.00            528             0
ngssummer2024  savvasc            2024-7         223.21          0.02         0.00            564             0
ngssummer2024  savvasc            2024-8           0.00          0.02         0.00            564             0
ngssummer2024  simonnn            2024-7         173.29          0.01         0.00            579             0
ngssummer2024  simonnn            2024-8           0.00          0.01         0.00            579             0
```

---

:::{.callout-tip title="Accounting Tips"}
- You can pipe the accounting output into `grep` to isolate specific users and/or months:

```{.bash}
gdk-project-usage -u -p <project-name> | grep <username> | grep <period>
```

&nbsp;

- all the accounting outputs can be saved into a file, which you can later open for example as Excel sheet.

Example:
```{.bash}
gdk-project-usage > accountingGDK.csv
```
:::

---

:::{.callout-tip title="Private files or folders"}
You have a folder or a file into the project which you do not want to share: Use 

```{.bash}
chmod -R go-rwx <file or folder>
```

&nbsp;

which you can revert using

```{.bash}
chmod -R go+rwx <file or folder>
```
:::

## Folders management

Have a coherent folder structure - your future self will thanks.

![Example of structure, which backs up raw data and analysis](img/structure.png){width=400px fig-align="center"}

You can do it with a script which downloads and execute with the command below:
```{.bash}
curl https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/main/Scripts/populate_project.sh | bash
```

---

If your project has many users, a good structure can be

![](img/multistructure.png){width=400px fig-align="center"}



&nbsp; 

Do that with these commands

```{.bash}
mkdir -p Backup/Data Workspaces/username1 Workspaces/username2
ln -s Backup/Data/ Data
```
and making each user to run the script in its folder

```{.bash}
cd Workspaces/username1
curl https://raw.githubusercontent.com/hds-sandbox/GDKworkshops/main/Scripts/populate_project.sh | bash
```

---

:::{.callout-warning title="MUST-KNOWs for a GDK project" layout-align="center"}
- remove **unused intermediate files**
    - unused and forgotten object filling up storage
- backup **only the established truth** of your analysis
    - in other words the very initial data of your analysis, and the scripts
- **outputs of many files** should be removed or zipped together into one 
    - otherwise GDK indexes all of them: slow!!!

&nbsp;

**Backup cost >>> Storage cost >> Computation cost**
:::

# Downloads and Copies

- Downloads from Internet to GDK
- Uploads from a local PC to GDK
- Downloads from GDK to a local PC
- Transfer data between GDK and another cluster
- Graphical interface for download/upload with GDK

---

Data transfer amongst the web, GDK and your PC is an everyday action which you can easily perform.

:::{.callout-warning}
Downloads should **always** happens on the `front-end` nodes, and never using a compute node when working on `GenomeDK`
:::

## Download with wget

`wget` is a utility for **command-line-based downloads**. It is already installed on `GenomeDK` and works with `http`, `https`, `ftp` protocols.

&nbsp;

Example:

```{.bash}
wget -O ./output.png \
     -c \
     -b \
     https://example.com/image.png
```
downloads a `png` file and saves it as `output.png` (option `O`), downloads in background (`-b`) and if the download was interrupted earlier, it retrieves it from where it stopped (`-c`).

---

`wget` has many options you can use, but what shown in the example above is what you need most times. You can see them with the command

```{.bash}
wget --help
```

&nbsp;

Also, you can find [this cheatsheet](https://opensource.com/sites/default/files/gated-content/osdc_cheatsheet-wget-2021.10.21.pdf) useful for remembering the commands to most of the things you can think about downloading files using wget. [At this page](https://opensource.com/article/21/10/linux-wget-command) there are also some concrete examples for `wget`.

## SCP transfer

`SCP` (Secure Copy Protocol) can transfer files securely

- between a LOCAL and a REMOTE host (your PC and GDK)
- between TWO REMOTE hosts (GDK and another cluster)

&nbsp;

You can use it to transfer files **from your pc to GenomeDK and viceversa**, but also **between GenomeDK and another computing cluster** (for example, downloading data from a collaborator, which resides on a different remote computing system).

---

To copy a file **to GenomeDK** from your local computer:
```{.bash}
scp /home/my_laptop/Documents/file.txt \
    username@login.genome.au.dk:/home/username/my_project/
```

&nbsp;

The **inverse operation** just changes the order of the sender and receiver:
```{.bash}
scp username@login.genome.au.dk:/home/username/my_project/file.txt \
    /home/my_laptop/Documents/
```

---

If you want to copy an entire folder, use the option `-r` (recursive copy). The previous examples become

```{.bash}
scp -r /home/my_laptop/Documents/folder \
       username@login.genome.au.dk:/home/username/my_project/
```

&nbsp;

and

```{.bash}
scp -r username@login.genome.au.dk:/home/username/my_project/folder \
       /home/my_laptop/Documents/
```

&nbsp;

A few more options are available and you can see them with the command ``` scp --help ```.

## Rsync transfer

Differently from `scp`, you can use `rsync` to **syncronize files and folders between two locations**. It copies only the changes in the data and not all of it every time.

&nbsp;

Copying a file or a folder between your computer and `GenomeDK` works exactly as in `scp`. For example

```{.bash}
rsync --partial --progress -r \
      username@login.genome.au.dk:/home/username/my_project/folder \
      /home/my_laptop/Documents/
```

where we add `-progress` to show a progress bar and `--partial` to retrieve interrupted downloads

## Interactive transfer

You can also do transfering with an interactive software, such as `Filezilla`, which  has an easy interface. [Download Filezilla](https://filezilla-project.org/download.php?type=client).

&nbsp;

When done, open `Filezilla` and use the following information on the login bar:

- Host: `login.genome.au.dk`
- Username, Password: your `GenomeDK` username and password
- Port: `22`

---

Press on `Quick Connect`. As a result, you will establish a secure connection to `GenomeDK`. On the left-side browser you can see your local folders and files. On the right-side, the folders and files on `GenomeDK` starting from your `home`.\

![](./img/filezilla1.png){fig-align="center"}

---

If you right-click on any local file or folder, you can **upload** it immediately, or **add it to the transfer queue**. The file will end up in the selected folder of the right-side browser.

![](./img/filezilla2.png){fig-align="center"}

---

The **download** process works similarly using the right-side browser and choosing the destination folder on the left-side browser.

![](./img/filezilla3.png){fig-align="center"}

---

If you have created a queue, this will be shown at the bottom of the window as a list. You can inspect destination folders from there and choose other options such as transfer priority.

![](./img/filezilla4.png){fig-align="center"}

To start a queue, use `CTRL + P`, `Transfer --> Process Queue` or press  the button ![](./img/filezilla5.png){width=100} on the toolbar.

# Package/Environment management

&nbsp;

Properly managing your **software and its dependencies** is fundamental for reproducibility

## Virtual environments

Each project needs specific software versions dependent on each other for **reproducibility** - without interferring with other projects.

&nbsp;

:::{.callout-note title="Definition"}
A **virtual environment** keeps project-specific softwares and their dependencies separated 

&nbsp;

A **package manager** is a software that can retrieve, download, install, upgrade packages **easily and reliably**
:::
---

![](./img/virtualenvs.png)

## Conda

&nbsp;

Conda is **both** a virtual environment and a package manager.

- easy to use and understand
- can handle quite big environments
- environments are easily shareable
- a [large archive](https://anaconda.org) (Anaconda) of packages
- active community of people archiving their packages on Anaconda

## Installation

Just download and execute the installer by
```{.bash}
wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O miniforge.sh
chmod +x miniforge.sh
bash miniforge.sh -b
./miniforge3/bin/conda init bash
```

&nbsp;

After a few `ENTER`s and `YES`'s you should get the installation done. Run

```{.bash}
source ~/.bashrc
```

and doublecheck that `conda` works:

```{.bash}
conda info
```

---

## Conda Configuration

You can add some default *channels* where to find archived packages. Here are some tipycal ones

```{.bash}
conda config --append channels bioconda
conda config --append channels genomedk
conda config --append channels r
conda config --append channels conda-forge
```

We tell `conda` to look into channels in the order specified above. We also avoid opening the `base` environment (where `conda` is installed) at login.

```{.bash}
conda config --set channel_priority strict
conda config --set auto_activate_base false
```

## Base environment

`base` is the environment containing conda itself. The current environment is in your prompt in round brackets.

```{.bash}
(environment) [samuele@fe-open-02 ~]$
```

We update Conda with `libmamba solver` - a lot faster in installing many packages at once.

```{.bash}
conda install -n base --yes conda-libmamba-solver
conda config --set solver libmamba
```

:::{.callout-warning title="Don't touch the Base"}
This is **the only time** you should install in the `base` environment! You might otherwise ruin the conda installation.
:::

## Create an environment

An empty environment called `test_1`:

```{.bash}
conda create -n test_1
```

&nbsp;

You can list all the environments available:

```{.bash}
conda env list
```
```
> # conda environments:
> #
> base      *  /home/samuele/miniconda3
> test_1       /home/samuele/miniconda3/envs/test_1
```

:::{.callout-note}
An environment is in reality a folder, which contains all installed packages and other configurations and utilities
:::

## Activate and deactivate

To use an environment we activate it:

```{.bash}
conda activate test_1
```
From now on, all installed softwares and packages will be available. `(test_1)` is now shown in your prompt.

&nbsp;

Deactivation happens by

```{.bash}
conda deactivate
```

## Manage an environment

### Package installation

Conda puts together the dependency trees of requested packages to find all compatible dependencies versions.

![Figure: A package's dependency tree with required versions on the edges](img/condatree.png)

---

To install a specific package in your environment, search it on [anaconda.org](https://anaconda.org):

![Figure: search DeSeq2 for R](img/anaconda1.png)

---

![Figure: suggested commands to install the package](img/anaconda2.png){width=10cm}

:::{.callout-note title="Repositories"}

packages are archived in repositories. Typical ones are `bioconda`, `conda-forge`, `r`, `anaconda`.

`conda-forge` packges are often more up-to-date, but a few times show compatibility problems with other packages.
:::

---

Install a couple of packages in the activated environment - you can always specify a version restriction to each package:

```{.bash}
conda activate test_1
conda install bioconda::bioconductor-deseq2<=1.42.0 conda-forge::r-tidyr=1.3.1
```

:::{.callout-note}
To install two packages, you need more than a hundred installations! Those are all dependencies arising from the **comparison of dependency trees**.
:::

&nbsp;

Look for the package `tidyr` in your active environment:

```{.bash}
conda list | grep tidyr
```

---

### Installation from a list of packages

You can export all the packages you have installed over time in your environment:

```{.bash}
conda env export --from-history > environment.yml
```

which looks like 

```{.yaml}
name: test_1
channels:
 - bioconda
 - conda-forge
 - defaults
 - r
dependencies:
 - bioconda::bioconductor-deseq2
 - conda-forge::r-tidyr
```

---

The same command without `--from-history` will create a very long file with ALL dependencies:

```{.yaml}
name: test_1
channels:
  - bioconda
  - conda-forge
  - defaults
  - r
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - _r-mutex=1.0.1=anacondar_1
  - argcomplete=3.2.2=pyhd8ed1ab_0
  ...
```

This is guaranteed to work **only on a system with same OS and architecture** as GenomeDK (Linux and x86)!

---

You can use the `yml` file to create an environment:

&nbsp;

```
conda env create -p test_1_from_file -f ./environment.yml
```

&nbsp;

Environment files are very useful when you want to **share environments with others**, especially when the package list is long.

---

**Good practice:** You want to install a lot of packages in an environment? Clone it first!
If you break something, you still have the old copy.

```{.bash}
conda create -p test_1_cloned --clone test_1
```

&nbsp;

If installations in the cloned environment go fine, then you can remove it 

```{.bash}
conda env remove -n test_1_cloned
```

and repeat the installations on the original one.

---

## Useful links for conda:

- [Conda cheat sheet](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf) with all the things you can do to manage environments

- [Anaconda](http://anaconda.org) where you can search for packages

# Running a Job

&nbsp;

Running programs on a computing cluster happens through **jobs**. 

&nbsp;

Learn how to get hold of **computing resources** to run your programs.

## What is a job on a HPC

A computational task **executed on requested HPC resources** (computing nodes), which are handled by the **queueing system** (SLURM).

![](img/Job-on-cluster.png){fig-align="center"}

---


The command `gnodes` will tell you if there is heavy usage across the computing nodes

![Usage of computing nodes. Each node has a name (e.g. cn-1001). The symbols for each node mean running a program (`0`), assigned to an user (`_`) and available (`.`)](./img/gnodes.png)

If you want to venture more into checking the queueing status, Moi has done [a great interactive script](https://github.com/MoiColl/cluster_status) in R Shiny for that.

---

Front-end nodes are limited in memory and power, and **should only be for basic operations** such as

- starting a new project

- small folders and files management

- small software installations

and in general you **should not** use them to run computations. This might slow down other users.

---

## Interactive jobs

Useful to run a **non-repetitive task interactively**

Examples: 

- splitting by chromosome that one `bam` file you just got 

- open `python`/`R` and do some statistics 

- compress/decompress multiple files, maybe in parallel

Once you exit from the job, anything running into it will stop.

---

To run an interactive job simply use the command

```
[fe-open-01]$ srun --mem=<GB_of_RAM>g -c <nr_cores> --time=<days-hrs:mins:secs>  --account=<project_name> --pty /bin/bash
```

For example

```
[fe-open-01]$ srun --mem=32g -c 2 --time=6:0:0  --account=<project_name> --pty /bin/bash
```

The **queueing system** makes you wait based on the resources you ask and how busy the nodes are. When you get **assigned a node**, the resources are available. The node name is **shown in the prompt**.

```
[<username>@s21n32 ~]$
```

## Batch script (sbatch)

Useful to **run a program non-interactively**, usually for longer time than a short interaction. A batch script contains 

- the desired **resources**
- the sequence of **commands** to be executed

and

- has a filename **without spaces** (forget spaces from now on)
---

### Example 

A file called `align.sh` such that:

```{.bash}
#!/bin/bash
#SBATCH --account my_project
#SBATCH --cpus-per-task= 8
#SBATCH --mem 16g
#SBATCH --time 04:00:00

#activate environment
eval "$(conda shell.bash hook)"
conda activate bam_tools
#index the reference file
bwa-mem2 index reference/chr2.fa
#align data
bwa-mem2 -t 8 reference/chr2.fa \
             genomes/S_Korean-2.region.fq.gz \
        | samtools sort \
            -@ 7 \
            -n \
            -O BAM \
        > alignment/S_Korean-2.sorted.bam

exit 0
```

---

Send the script to the queueing system:

```{.bash}
sbatch align.sh
```
```
Submitted batch job 33735298
```

&nbsp;

Interrogate SLURM about the specific job

```{.bash}
jobinfo 33735298
```

```
>Name                : align.sh
>User                : samuele
>Account             : my_project
>Partition           : short
>Nodes               : s21n43
>Cores               : 8
>GPUs                : 0
>State               : RUNNING
>...
```

---

or about all the queued jobs

```{.bash}
squeue -u <username>
```

```
>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
>33735928     short align.sh  samuele  R       1:12      1 s21n43
```

&nbsp;

If you change your mind and want to cancel a job:

```{.bash}
scancel 33735928
```

---

:::{.callout-tip}
To observe in real time the output of  the job, refresh the last lines of the log file for that job:

```{.bash}
watch tail align.sh-33735928.out
```
&nbsp;

To look at the whole log (not in real time), run at any time

```{.bash}
less -S align.sh-33735928.out
```

Checking the log files can be useful for debugging, when for example a command gives an error and the job interrupts before its end.
:::

## Other ways of running jobs

Beyond `sbatch`, you can use other tools for workflows which are

- **modular and composable**: sequences of commands can be applied in various contexts, composed together in the desired ordering
- **scalable and parallel** handling many sequences of operations parallelly or interdependently
- **flexible** where repetitive operations can be automatized over multiple applications

---

Some workflow tools:

- [Snakemake](https://snakemake.readthedocs.io/en/stable/)
- [NextFlow](https://www.nextflow.io/)
- [Gwf](https://gwf.app/)

&nbsp;

`Gwf` has an easy `python` syntax instead of its own language to write workflows.

&nbsp;

Learning a workflow language takes some time commitment, but it is worth the effort.
